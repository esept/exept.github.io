<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Diary-05-2020</title>
    <url>/2020/05/10/diary/</url>
    <content><![CDATA[<p>这里曾经，依旧是我的五月<br>岁月漫长，但是值得等待<br> <a id="more"></a></p>
<h2 id="2020-05"><a href="#2020-05" class="headerlink" title="2020-05"></a>2020-05</h2><p>自己剖析自己是一件挺可怕的事情，因为有的时候一旦发现自己做那件事的原因竟然是因为这样的一个理由，如果这样的原因是一个不愿被自己接受的结果，那面对自己都会有一点不情愿<br>对于爬虫这个东西真的是麻烦，做个项目竟然还要自己购买代理</p>
<p>今天不知道是第几次试图创建图片流失败了<br>我基本上已经要放弃尝试了，现在前端的东西一点也不会，完全就是按照网上的教程来进行自己的操作<br>然后嘞，我发现现在这样子的一个环境还是很适合自己的<br>因为很有感觉<br>然后发现自己创建更新内容和前端，访问量轻轻松松上百</p>
<p>Emmm。。。</p>
<p>想回国的时候去北京吃一堆想吃的东西</p>
<p>今天先这样子吧</p>
<p>喜欢下雨天。</p>
]]></content>
      <categories>
        <category>日记</category>
      </categories>
      <tags>
        <tag>日记</tag>
      </tags>
  </entry>
  <entry>
    <title>他是诗人</title>
    <url>/2020/05/08/doc/</url>
    <content><![CDATA[<p>他曾说 我爱你<br>就像叶爱飘零 风爱游荡<br>他曾禁锢在个人世界<br>无人读懂 欢喜惆怅<br> <a id="more"></a></p>
<p>让岁月抚平忧伤<br>年华换成怅惘<br>星空月夜伴随凄凉<br>独自扼杀希望</p>
<p>谁说诗人习惯独自流浪<br>只不过从未找到过家的方向<br>他在尝试抚平心灵创伤<br>用诗来抒发梦想</p>
<p>他也曾尝过爱情<br>决绝 苦涩 需要勇气<br>他不许任何人亵渎这经历<br>就像他人亵渎自己</p>
<p>他早迷失在混乱世界<br>等待爱人将他救起<br>他却说我是诗人<br>悲伤才是对的记忆</p>
<p>他在等人帮他抹去泪水<br>等人填补空洞心伤<br>诗人强撑着精神病体<br>说着自由 理应继续彷徨</p>
<p>现在的我向往自由与孤独<br>现在的我甘愿流浪<br>诗人不停地大声吟唱<br>天空的雨滴浸透出点点荒凉</p>
<p>诗人的梦里有他想要的一切<br>却不知从何记起<br>他在夜里悲伤的哭泣<br>谁又见过他的无助模样</p>
<p>他还在用低沉的声音吟唱<br>唱出对世界无尽的失望<br>海阔天空和万丈悬崖其实一样<br>都会抛下久违的梦想</p>
<p>诗人披着月光<br>低吟清唱着他的忧伤<br>他说坚强一点<br>就像月光不惧朝阳</p>
<p>他在慢慢游荡<br>渐渐走向陌生的远方<br>他也不想背井离乡<br>只因这里过分凄凉</p>
<p>其实诗人早就死亡<br>只剩他的躯体被迫流浪<br>他的灵魂灰飞烟灭<br>却无人惋惜他的坚强</p>
<p>你是否曾望见过诗人的孤寂背影<br>就像月光才是最柔美的光芒<br>人们不知是否该去祭奠<br>来安抚孤魂的游荡带来的离殇</p>
<p>固执的他 说 我是诗人<br>怎敢以流泪缓解悲伤<br>他说我喜欢孤身一人 只身迎接<br>坎坷路途上的天堂</p>
]]></content>
      <categories>
        <category>思考与遐想</category>
      </categories>
      <tags>
        <tag>采集忘却</tag>
      </tags>
  </entry>
  <entry>
    <title>大多数的我</title>
    <url>/2020/05/06/%E5%A4%A7%E5%A4%9A%E6%95%B0%E7%9A%84%E6%88%91/</url>
    <content><![CDATA[<p>少数的我<br>梦见了故乡</p>
<a id="more"></a>
<p>从未回去那里的魂魄<br>抢夺去了风中<br>应见泪水相拥的画面<br>战乱连年<br>仅有的雨也成了雪<br>融入这暴戾的暖炉<br>痛不知思绪的去向<br>只能肆意地游荡在躯体<br>千万之一相见的几率<br>释怀于死前<br>无言的喧寂<br>大多数的我<br>梦不见故乡<br>身处于不知何方 无可奈何<br>指引的信号刻画于手臂<br>感官隐于黑暗<br>轻道  恭喜</p>
]]></content>
      <categories>
        <category>思考与遐想</category>
      </categories>
      <tags>
        <tag>采集忘却</tag>
      </tags>
  </entry>
  <entry>
    <title>爬虫</title>
    <url>/2020/05/13/%E7%88%AC%E8%99%AB/</url>
    <content><![CDATA[<h1 id="模拟请求头与代理IP"><a href="#模拟请求头与代理IP" class="headerlink" title="模拟请求头与代理IP"></a>模拟请求头与代理IP</h1><h2 id="创建项目"><a href="#创建项目" class="headerlink" title="创建项目"></a>创建项目</h2><ol>
<li>找到目标文件夹</li>
<li>创建项目  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ scrapy startproject &#39;ProjectName&#39;</span><br><span class="line">$ cd &#39;ProjectName&#39;</span><br><span class="line">$ scrapy genspider &#39;Name&#39; &quot;网站域名&quot;</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h2 id="配置Setting"><a href="#配置Setting" class="headerlink" title="配置Setting"></a>配置Setting</h2><ol>
<li><p>关闭Robot协议</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ROBOTSTXT_OBEY = <span class="literal">False</span></span><br></pre></td></tr></table></figure></li>
<li><p>开启Download_Delay</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">DOWNLOAD_DELAY = <span class="number">3</span></span><br></pre></td></tr></table></figure></li>
<li><p>设置默认请求头</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">DEFAULT_REQUEST_HEADERS = &#123;</span><br><span class="line">  <span class="string">'Accept'</span>: <span class="string">'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'</span>,</span><br><span class="line">  <span class="string">'Accept-Language'</span>: <span class="string">'en'</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>开启下载中间件与管道文件</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">DOWNLOADER_MIDDLEWARES = &#123;</span><br><span class="line">   <span class="string">'zhaobiao.middlewares.ZhaobiaoDownloaderMiddleware'</span>: <span class="number">543</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">'zhaobiao.pipelines.ZhaobiaoPipeline'</span>: <span class="number">300</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>设置请求头 Cookie和User-Agent</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">DEFAULT_REQUEST_HEADERS = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36'</span>,</span><br><span class="line">    <span class="string">'Cookie'</span>:<span class="string">'登陆后的cookie'</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h2 id="Spiders-项目文件"><a href="#Spiders-项目文件" class="headerlink" title="Spiders/项目文件"></a>Spiders/项目文件</h2><h3 id="设置存储的数据格式"><a href="#设置存储的数据格式" class="headerlink" title="设置存储的数据格式"></a>设置存储的数据格式</h3><p>即爬虫项目里需要爬取的内容</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sql_data = dict(</span><br><span class="line">      projectcode=<span class="string">''</span>,  <span class="comment"># 项目编号</span></span><br><span class="line">      web=<span class="string">''</span>,  <span class="comment"># 信息来源网站</span></span><br><span class="line">      keyword=<span class="string">''</span>,  <span class="comment"># 关键字</span></span><br><span class="line">      detail_url=<span class="string">''</span>,  <span class="comment"># 招标详细页网址</span></span><br><span class="line">      title=<span class="string">''</span>,  <span class="comment"># 第三方网站发布标题</span></span><br><span class="line">      toptype=<span class="string">''</span>,  <span class="comment"># 信息类型</span></span><br><span class="line">      province=<span class="string">''</span>,  <span class="comment"># 归属省份</span></span><br><span class="line">      product=<span class="string">''</span>,  <span class="comment"># 产品范畴</span></span><br><span class="line">      industry=<span class="string">''</span>,  <span class="comment"># 归属行业</span></span><br><span class="line">      tendering_manner=<span class="string">''</span>,  <span class="comment"># 招标方式</span></span><br><span class="line">      publicity_date=<span class="string">''</span>,  <span class="comment"># 招标公示日期</span></span><br><span class="line">      expiry_date=<span class="string">''</span>,  <span class="comment"># 招标截止时间</span></span><br><span class="line">  )</span><br></pre></td></tr></table></figure>

<h3 id="设置Form表单的数据格式"><a href="#设置Form表单的数据格式" class="headerlink" title="设置Form表单的数据格式"></a>设置Form表单的数据格式</h3><p>即从网站可以获取的数据</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">form_data = dict(</span><br><span class="line">       infoClassCodes=<span class="string">''</span>,</span><br><span class="line">       rangeType=<span class="string">''</span>,</span><br><span class="line">       projectType=<span class="string">'bid'</span>,</span><br><span class="line">       fundSourceCodes=<span class="string">''</span>,</span><br><span class="line">       dateType=<span class="string">''</span>,</span><br><span class="line">       startDateCode=<span class="string">''</span>,</span><br><span class="line">       endDateCode=<span class="string">''</span>,</span><br><span class="line">       normIndustry=<span class="string">''</span>,</span><br><span class="line">       normIndustryName=<span class="string">''</span>,</span><br><span class="line">       zone=<span class="string">''</span>,</span><br><span class="line">       zoneName=<span class="string">''</span>,</span><br><span class="line">       zoneText=<span class="string">''</span>,</span><br><span class="line">       key=<span class="string">''</span>,  <span class="comment"># 搜索的关键字</span></span><br><span class="line">       pubDateType=<span class="string">''</span>,</span><br><span class="line">       pubDateBegin=<span class="string">''</span>,</span><br><span class="line">       pubDateEnd=<span class="string">''</span>,</span><br><span class="line">       sortMethod=<span class="string">'timeDesc'</span>,</span><br><span class="line">       orgName=<span class="string">''</span>,</span><br><span class="line">       currentPage=<span class="string">''</span>,  <span class="comment"># 当前页码</span></span><br><span class="line">   )</span><br></pre></td></tr></table></figure>
<h3 id="定义start-requests-self"><a href="#定义start-requests-self" class="headerlink" title="定义start_requests(self)"></a>定义start_requests(self)</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(self)</span>:</span></span><br><span class="line"></span><br><span class="line">    form_data = self.form_data</span><br><span class="line">    form_data[<span class="string">'key'</span>] = <span class="string">'路由器'</span></span><br><span class="line">    form_data[<span class="string">'currentPage'</span>] = <span class="string">'2'</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">yield</span> scrapy.FormRequest( <span class="comment"># 对FormRequest的封装，可以提交表单数据</span></span><br><span class="line">        url = <span class="string">'http://ss.ebnew.com/tradingSearch/index.htm'</span>,</span><br><span class="line">        formdata= form_data,<span class="comment"># 传递字典对象</span></span><br><span class="line">        callback=self.parse_page1,<span class="comment"># 定义回调函数</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_page1</span><span class="params">(self,response)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'2.html'</span>,<span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(response.body) <span class="comment"># 写入到本地</span></span><br></pre></td></tr></table></figure>

<h3 id="创建start文件"><a href="#创建start文件" class="headerlink" title="创建start文件"></a>创建start文件</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> cmdline</span><br><span class="line"></span><br><span class="line">cmdline.execute(<span class="string">'scrapy crawl bilian'</span>.split())</span><br></pre></td></tr></table></figure>

<h2 id="配置代理ip"><a href="#配置代理ip" class="headerlink" title="配置代理ip"></a>配置代理ip</h2><p>找到middlewares里的class ZhaobiaoDownloaderMiddleware 里的<br>process_request</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 需要倒入包</span></span><br><span class="line"><span class="keyword">import</span> urllib.request <span class="keyword">as</span> ur <span class="comment"># 使用ur.urlopen</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">process_request</span><span class="params">(self, request, spider)</span>:</span></span><br><span class="line">        request.meta[<span class="string">'proxy'</span>] = <span class="string">'http://'</span> + ur.urlopen(<span class="string">'代理IP地址'</span>).read().decode(<span class="string">'utf-8'</span>).strip() <span class="comment"># 设置代理</span></span><br></pre></td></tr></table></figure>
<p>.strip（）去掉首位换行符</p>
<h1 id="页面中的数据过滤提取"><a href="#页面中的数据过滤提取" class="headerlink" title="页面中的数据过滤提取"></a>页面中的数据过滤提取</h1>]]></content>
  </entry>
  <entry>
    <title>如果我想你</title>
    <url>/2020/05/08/%E5%A6%82%E6%9E%9C%E6%88%91%E6%83%B3%E4%BD%A0/</url>
    <content><![CDATA[<p>愿你能从他身上听到你想听的话<br>单调却挂念的话<br>有没有一些<br>来自我这个人渣</p>
<a id="more"></a>
<p>记忆的沙 霜冻的画<br>故乡的花已经发芽<br>牵着希望的手悄然滑下<br>我还是怀念我残破的家<br>音乐盒的主人公默念牵挂<br>没有你的口信<br>我不敢安家<br>你还留着我寄存的味道吗<br>书写下的话 让天空散漫着花<br>那景象是我从未见过的<br>我想问你可知爱字如何落下<br>却无法否认那是我从未见过的回答</p>
]]></content>
      <categories>
        <category>思考与遐想</category>
      </categories>
      <tags>
        <tag>采集忘却</tag>
      </tags>
  </entry>
</search>
